{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramFiles\\miniconda3\\envs\\pyspch_edit\\lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pyspch\n",
    "import pyspch.nn\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths \n",
    "\n",
    "# public = /users/spraak/spchlab/public_html/pyspch/timit/ (final project)\n",
    "# private = /esat/spchtemp/scratch/bvandyck/timit/ (dev project, training models on HTCondor)\n",
    "remote_path = 'https://homes.esat.kuleuven.be/~spchlab/pyspch/timit/'\n",
    "\n",
    "if True:\n",
    "    # (@remote, personal machine, bvandyck) \n",
    "    timit_path = 'W:/timit/CDdata/timit/' # to extract corpus, features, labels\n",
    "    write_path = 'Z:/scratch/bvandyck/timit/' # to write corpus, features, labels\n",
    "    read_path = 'Z:/scratch/bvandyck/timit/' # to read corpus, features, labels\n",
    "\n",
    "if False:\n",
    "    # (@esat, bvandyck)\n",
    "    timit_path = '/users/spraak/spchdata/timit/CDdata/timit/' # to extract corpus, features, labels\n",
    "    write_path = '/esat/spchtemp/scratch/bvandyck/timit/' # to write corpus, features, labels\n",
    "    read_path = '/esat/spchtemp/scratch/bvandyck/timit/' # to read corpus, features, labels\n",
    "    \n",
    "if False:\n",
    "    # (@esat, spchlab)\n",
    "    timit_path = '/users/spraak/spchdata/timit/CDdata/timit/' # to extract corpus, features, labels\n",
    "    write_path = '/users/spraak/spchlab/public_html/pyspch/timit/' # to write corpus, features, labels\n",
    "    read_path = '/users/spraak/spchlab/public_html/pyspch/timit/' # to read corpus, features, labels\n",
    "\n",
    "os.chdir(write_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare (or read) TIMIT corpus "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus contains 6300 files\n"
     ]
    }
   ],
   "source": [
    "# prepare TIMIT corpus \n",
    "prepare_corpus = False\n",
    "read_corpus = True\n",
    "write_corpus_path = write_path + 'data/'\n",
    "read_corpus_path = read_path + 'data/'\n",
    "\n",
    "if prepare_corpus:\n",
    "    \n",
    "    # get corpus from directory \n",
    "    timit_corpus = pyspch.timit.get_timit_corpus(timit_path) \n",
    "\n",
    "    # corpus subsets (train/test, additional)\n",
    "    timit_train = pyspch.timit.filter_list_timit(timit_corpus, split='train')\n",
    "    timit_test = pyspch.timit.filter_list_timit(timit_corpus, split='test')\n",
    "    timit_train_dr1 = pyspch.timit.filter_list_timit(timit_corpus, split='train', region='dr1')\n",
    "    timit_test_dr1 = pyspch.timit.filter_list_timit(timit_corpus, split='test', region='dr1')\n",
    "    \n",
    "    # write corpus to disk\n",
    "    os.makedirs(write_corpus_path, exist_ok=True)\n",
    "    pyspch.write_txt(timit_corpus, write_corpus_path + 'timit.corpus')\n",
    "    \n",
    "    # write corpus subsets to disk\n",
    "    pyspch.write_txt(timit_train, write_corpus_path + 'timit_train.corpus')\n",
    "    pyspch.write_txt(timit_test, write_corpus_path + 'timit_test.corpus')\n",
    "    pyspch.write_txt(timit_train_dr1, write_corpus_path + 'timit_train_dr1.corpus')\n",
    "    pyspch.write_txt(timit_test_dr1, write_corpus_path + 'timit_test_dr1.corpus')\n",
    "\n",
    "    # extract meta data and write to disk\n",
    "    timit_meta = pyspch.timit.get_timit_metadata(timit_corpus)\n",
    "    timit_meta.to_csv(write_corpus_path + 'timit.meta', sep='\\t', index=False, header=False)\n",
    "\n",
    "if read_corpus:\n",
    "    \n",
    "    # read corpus and meta data\n",
    "    timit_corpus = pyspch.read_data_file(read_corpus_path + 'timit.corpus')\n",
    "    meta = pyspch.read_dataframe(read_corpus_path + \"timit.meta\")\n",
    "   \n",
    "# print\n",
    "print(f'Corpus contains {len(timit_corpus)} files')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read TIMIT data (wav)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize SpchData with corpus\n",
    "timit_data = pyspch.nn.SpchData(timit_corpus)\n",
    "\n",
    "# read signals (wav-data) from disk ~ 15-25min\n",
    "sample_rate_wav = 16000\n",
    "timit_data.read_signals(timit_path, sample_rate_wav, extension='.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract TIMIT features (for exercise sessions)\n",
    "- Write feature to disk for each audio file\n",
    "- Extract aligned labels (TIMIT61) and save complete setup as pickled dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mel filterbank cepstral coeffients (mfcc13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32mD:\\ProgramFiles\\miniconda3\\envs\\pyspch_edit\\lib\\os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[1;34m(name, mode, exist_ok)\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m         \u001b[0mmkdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileExistsError\u001b[0m: [WinError 183] Cannot create a file when that file already exists: 'Z:/scratch/bvandyck/timit/data/mfcc13/test/dr2/fpas0'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19336\\3028594718.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# extract and write features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mpyspch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_dirs_for_corpus\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrite_feature_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimit_corpus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[0mtimit_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract_features_from_signals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mtimit_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrite_feature_path\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# ~ 25min\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\gitlab\\psi\\compi1234\\pyspch_edit\\pyspch\\core\\timit.py\u001b[0m in \u001b[0;36mmake_dirs_for_corpus\u001b[1;34m(root_path, rel_path_list)\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmake_dirs_for_corpus\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrel_path_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mrel_path\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrel_path_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m         \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot_path\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrel_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m755\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m def get_timit_corpus(path, \n",
      "\u001b[1;32mD:\\ProgramFiles\\miniconda3\\envs\\pyspch_edit\\lib\\os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[1;34m(name, mode, exist_ok)\u001b[0m\n\u001b[0;32m    221\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m         \u001b[0mmkdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m         \u001b[1;31m# Cannot rely on checking for EEXIST, since the operating system\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# A. Mel Frequency Cepstral Coeffients (mfcc13)\n",
    "write_feature_path = write_path + 'data/mfcc13/'\n",
    "\n",
    "# arguments\n",
    "feature_args = {\n",
    "    'spg': None, 'Deltas': None, 'Norm': None,\n",
    "    'sample_rate': 16000, 'f_shift': 0.01, 'f_length': 0.03,\n",
    "    'preemp': 0.97, 'window': 'hamm', 'mode': 'dB',  \n",
    "    'n_mels': 24, 'n_cep': 13 \n",
    "    }\n",
    "\n",
    "# extract features\n",
    "timit_data.extract_features_from_signals(feature_args)\n",
    "\n",
    "if False:\n",
    "     \n",
    "    # write features\n",
    "    pyspch.timit.make_dirs_for_corpus(write_feature_path, timit_corpus)\n",
    "    timit_data.write_features(write_feature_path)\n",
    "\n",
    "    # write feature_args \n",
    "    feature_args_fname = os.path.join(write_feature_path, 'feature_args.json')\n",
    "    pyspch.write_json(feature_args, feature_args_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extraction can also be done while reading the signals (wav-data).\n",
    "# This requires less memory (since signals are not kept in memory).\n",
    "# However, here we first load signals, then extract features, such that\n",
    "# different feature extraction's can be performed, without re-reading the signals.\n",
    "if False:\n",
    "    # on the fly looks like:\n",
    "    timit_data.extract_features(timit_path, feature_args, extension='.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup as pickled dataframe\n",
    "write_setup_path = write_path + 'data/mfcc13/'\n",
    "\n",
    "if False:\n",
    "    \n",
    "    # TIMIT61 phoneme labels (phn)\n",
    "    read_label_path = read_path + 'data/segmentation/'\n",
    "    label_args = {'pad': 'h#', 'extension': '.phn'}\n",
    "    shift = feature_args['f_shift'] * feature_args['sample_rate']\n",
    "    timit_data.extract_alligned_labels(read_label_path, shift, label_args['pad'], label_args['extension'])\n",
    "\n",
    "    # split Spchdata into train/test\n",
    "    train_data = timit_data.subset_with_regex(f'.*(train)/.*')\n",
    "    test_data = timit_data.subset_with_regex(f'.*(test)/.*')\n",
    "\n",
    "    # to dataframe\n",
    "    train_df = train_data.to_dataframe()\n",
    "    test_df = test_data.to_dataframe()\n",
    "\n",
    "    # drop signals (wav-data)\n",
    "    train_df.drop(columns=['signals'], inplace=True)\n",
    "    test_df.drop(columns=['signals'], inplace=True)\n",
    "    \n",
    "    # write setup to disk\n",
    "    train_df.to_pickle(write_setup_path + 'train.pkl')\n",
    "    test_df.to_pickle(write_setup_path + 'test.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mel filterbanks (mel80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B. Mel filterbanks (mel80)\n",
    "write_feature_path = write_path + 'data/mel80/'\n",
    "\n",
    "# arguments\n",
    "feature_args = {\n",
    "    'spg': None, 'Deltas': None, 'Norm': None,\n",
    "    'sample_rate': 16000, 'f_shift': 0.01, 'f_length': 0.03,\n",
    "    'preemp': 0.97, 'window': 'hamm', 'mode': 'dB',\n",
    "    'n_mels': 80, 'n_cep': None\n",
    "    }\n",
    "\n",
    "# extract features\n",
    "timit_data.extract_features_from_signals(feature_args)\n",
    "\n",
    "if False:\n",
    "     \n",
    "    # write features\n",
    "    pyspch.timit.make_dirs_for_corpus(write_feature_path, timit_corpus)\n",
    "    timit_data.write_features(write_feature_path)\n",
    "\n",
    "    # write feature_args \n",
    "    feature_args_fname = os.path.join(write_feature_path, 'feature_args.json')\n",
    "    pyspch.write_json(feature_args, feature_args_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup as pickled dataframe\n",
    "write_setup_path = write_path + 'data/mel80/'\n",
    "\n",
    "if False:\n",
    "    \n",
    "    # TIMIT61 phoneme labels (phn)\n",
    "    read_label_path = read_path + 'data/segmentation/'\n",
    "    label_args = {'pad': 'h#', 'extension': '.phn'}\n",
    "    shift = feature_args['f_shift'] * feature_args['sample_rate']\n",
    "    timit_data.extract_alligned_labels(read_label_path, shift, label_args['pad'], label_args['extension'])\n",
    "\n",
    "    # split Spchdata into train/test\n",
    "    train_data = timit_data.subset_with_regex(f'.*(train)/.*')\n",
    "    test_data = timit_data.subset_with_regex(f'.*(test)/.*')\n",
    "\n",
    "    # to dataframe\n",
    "    train_df = train_data.to_dataframe()\n",
    "    test_df = test_data.to_dataframe()\n",
    "\n",
    "    # drop signals (wav-data)\n",
    "    train_df.drop(columns=['signals'], inplace=True)\n",
    "    test_df.drop(columns=['signals'], inplace=True)\n",
    "    \n",
    "    # write setup to disk\n",
    "    train_df.to_pickle(write_setup_path + 'train.pkl')\n",
    "    test_df.to_pickle(write_setup_path + 'test.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filterbanks (fb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C. Filterbanks (fb)\n",
    "write_feature_path = write_path + 'data/fb257/'\n",
    "\n",
    "# arguments\n",
    "feature_args = {\n",
    "    'spg': None, 'Deltas': None, 'Norm': None,\n",
    "    'sample_rate': 16000, 'f_shift': 0.01, 'f_length': 0.03,\n",
    "    'preemp': 0.97, 'window': 'hamm', 'mode': 'dB',\n",
    "    'n_mels': None, 'n_cep': None\n",
    "    }\n",
    "\n",
    "# extract features\n",
    "timit_data.extract_features_from_signals(feature_args)\n",
    "\n",
    "if True:\n",
    "     \n",
    "    # write features\n",
    "    pyspch.timit.make_dirs_for_corpus(write_feature_path, timit_corpus)\n",
    "    timit_data.write_features(write_feature_path)\n",
    "\n",
    "    # write feature_args \n",
    "    feature_args_fname = os.path.join(write_feature_path, 'feature_args.json')\n",
    "    pyspch.write_json(feature_args, feature_args_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup as pickled dataframe\n",
    "write_setup_path = write_path + 'data/fb257/'\n",
    "\n",
    "if True:\n",
    "    \n",
    "    # TIMIT61 phoneme labels (phn)\n",
    "    read_label_path = read_path + 'data/segmentation/'\n",
    "    label_args = {'pad': 'h#', 'extension': '.phn'}\n",
    "    shift = feature_args['f_shift'] * feature_args['sample_rate']\n",
    "    timit_data.extract_alligned_labels(read_label_path, shift, label_args['pad'], label_args['extension'])\n",
    "\n",
    "    # split Spchdata into train/test\n",
    "    train_data = timit_data.subset_with_regex(f'.*(train)/.*')\n",
    "    test_data = timit_data.subset_with_regex(f'.*(test)/.*')\n",
    "\n",
    "    # to dataframe\n",
    "    train_df = train_data.to_dataframe()\n",
    "    test_df = test_data.to_dataframe()\n",
    "\n",
    "    # drop signals (wav-data)\n",
    "    train_df.drop(columns=['signals'], inplace=True)\n",
    "    test_df.drop(columns=['signals'], inplace=True)\n",
    "    \n",
    "    # write setup to disk\n",
    "    train_df.to_pickle(write_setup_path + 'train.pkl')\n",
    "    test_df.to_pickle(write_setup_path + 'test.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mel filterbanks (mel24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D. Mel filterbanks (mel80)\n",
    "write_feature_path = write_path + 'data/mel24/'\n",
    "\n",
    "# arguments\n",
    "feature_args = {\n",
    "    'spg': None, 'Deltas': None, 'Norm': None,\n",
    "    'sample_rate': 16000, 'f_shift': 0.01, 'f_length': 0.03,\n",
    "    'preemp': 0.97, 'window': 'hamm', 'mode': 'dB',\n",
    "    'n_mels': 24, 'n_cep': None\n",
    "    }\n",
    "\n",
    "# extract features\n",
    "timit_data.extract_features_from_signals(feature_args)\n",
    "\n",
    "if True:\n",
    "     \n",
    "    # write features\n",
    "    pyspch.timit.make_dirs_for_corpus(write_feature_path, timit_corpus)\n",
    "    timit_data.write_features(write_feature_path)\n",
    "\n",
    "    # write feature_args \n",
    "    feature_args_fname = os.path.join(write_feature_path, 'feature_args.json')\n",
    "    pyspch.write_json(feature_args, feature_args_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup as pickled dataframe\n",
    "write_setup_path = write_path + 'data/mel24/'\n",
    "\n",
    "if True:\n",
    "    \n",
    "    # TIMIT61 phoneme labels (phn)\n",
    "    read_label_path = read_path + 'data/segmentation/'\n",
    "    label_args = {'pad': 'h#', 'extension': '.phn'}\n",
    "    shift = feature_args['f_shift'] * feature_args['sample_rate']\n",
    "    timit_data.extract_alligned_labels(read_label_path, shift, label_args['pad'], label_args['extension'])\n",
    "\n",
    "    # split Spchdata into train/test\n",
    "    train_data = timit_data.subset_with_regex(f'.*(train)/.*')\n",
    "    test_data = timit_data.subset_with_regex(f'.*(test)/.*')\n",
    "\n",
    "    # to dataframe\n",
    "    train_df = train_data.to_dataframe()\n",
    "    test_df = test_data.to_dataframe()\n",
    "\n",
    "    # drop signals (wav-data)\n",
    "    train_df.drop(columns=['signals'], inplace=True)\n",
    "    test_df.drop(columns=['signals'], inplace=True)\n",
    "    \n",
    "    # write setup to disk\n",
    "    train_df.to_pickle(write_setup_path + 'train.pkl')\n",
    "    test_df.to_pickle(write_setup_path + 'test.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load setup for exercise sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    \n",
    "    # read from disk\n",
    "    read_setup_path = write_path + 'data/mfcc13/'\n",
    "    train_df = pd.read_pickle(write_setup_path + 'train.pkl')\n",
    "    test_df = pd.read_pickle(write_setup_path + 'test.pkl')\n",
    "    \n",
    "    # dataframe to SpchData\n",
    "    train_data = pyspch.nn.DataFrame_to_SpchData(train_df)\n",
    "    test_data = pyspch.nn.DataFrame_to_SpchData(test_df)\n",
    "    print(train_data.corpus)\n",
    "    print(test_data.corpus)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "07bbb230afa188f6fcf784790a512a027d4aaebd8b449a47936f42b92e92fbab"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 ('pyspch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
