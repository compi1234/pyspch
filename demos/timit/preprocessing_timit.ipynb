{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramFiles\\miniconda3\\envs\\pyspch_edit\\lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pyspch\n",
    "import pyspch.nn\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths \n",
    "\n",
    "# public = /users/spraak/spchlab/public_html/pyspch/timit/ (final project)\n",
    "# private = /esat/spchtemp/scratch/bvandyck/timit/ (dev project, training models on HTCondor)\n",
    "remote_path = 'https://homes.esat.kuleuven.be/~spchlab/pyspch/timit/'\n",
    "\n",
    "if True:\n",
    "    # (@remote, personal machine, bvandyck) \n",
    "    timit_path = 'W:/timit/CDdata/timit/' # to extract corpus, features, labels\n",
    "    write_path = 'Z:/scratch/bvandyck/timit/' # to write corpus, features, labels\n",
    "    read_path = 'Z:/scratch/bvandyck/timit/' # to read corpus, features, labels\n",
    "\n",
    "if False:\n",
    "    # (@esat, bvandyck)\n",
    "    timit_path = '/users/spraak/spchdata/timit/CDdata/timit/' # to extract corpus, features, labels\n",
    "    write_path = '/esat/spchtemp/scratch/bvandyck/timit/' # to write corpus, features, labels\n",
    "    read_path = '/esat/spchtemp/scratch/bvandyck/timit/' # to read corpus, features, labels\n",
    "    \n",
    "if False:\n",
    "    # (@esat, spchlab)\n",
    "    timit_path = '/users/spraak/spchdata/timit/CDdata/timit/' # to extract corpus, features, labels\n",
    "    write_path = '/users/spraak/spchlab/public_html/pyspch/timit/' # to write corpus, features, labels\n",
    "    read_path = '/users/spraak/spchlab/public_html/pyspch/timit/' # to read corpus, features, labels\n",
    "\n",
    "os.chdir(write_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare (or read) TIMIT corpus "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus contains 6300 files\n"
     ]
    }
   ],
   "source": [
    "# prepare TIMIT corpus \n",
    "prepare_corpus = False\n",
    "read_corpus = True\n",
    "write_corpus_path = write_path + 'data/'\n",
    "read_corpus_path = read_path + 'data/'\n",
    "\n",
    "if prepare_corpus:\n",
    "    \n",
    "    # get corpus from directory \n",
    "    timit_corpus = pyspch.timit.get_timit_corpus(timit_path) \n",
    "\n",
    "    # corpus subsets (train/test, additional)\n",
    "    timit_train = pyspch.timit.filter_list_timit(timit_corpus, split='train')\n",
    "    timit_test = pyspch.timit.filter_list_timit(timit_corpus, split='test')\n",
    "    timit_train_dr1 = pyspch.timit.filter_list_timit(timit_corpus, split='train', region='dr1')\n",
    "    timit_test_dr1 = pyspch.timit.filter_list_timit(timit_corpus, split='test', region='dr1')\n",
    "    \n",
    "    # write corpus to disk\n",
    "    os.makedirs(write_corpus_path, exist_ok=True)\n",
    "    pyspch.write_txt(timit_corpus, write_corpus_path + 'timit.corpus')\n",
    "    \n",
    "    # write corpus subsets to disk\n",
    "    pyspch.write_txt(timit_train, write_corpus_path + 'timit_train.corpus')\n",
    "    pyspch.write_txt(timit_test, write_corpus_path + 'timit_test.corpus')\n",
    "    pyspch.write_txt(timit_train_dr1, write_corpus_path + 'timit_train_dr1.corpus')\n",
    "    pyspch.write_txt(timit_test_dr1, write_corpus_path + 'timit_test_dr1.corpus')\n",
    "\n",
    "    # extract meta data and write to disk\n",
    "    timit_meta = pyspch.timit.get_timit_metadata(timit_corpus)\n",
    "    timit_meta.to_csv(write_corpus_path + 'timit.meta', sep='\\t', index=False, header=False)\n",
    "\n",
    "if read_corpus:\n",
    "    \n",
    "    # read corpus and meta data\n",
    "    timit_corpus = pyspch.read_data_file(read_corpus_path + 'timit.corpus')\n",
    "    meta = pyspch.read_dataframe(read_corpus_path + \"timit.meta\")\n",
    "   \n",
    "# print\n",
    "print(f'Corpus contains {len(timit_corpus)} files')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read TIMIT data (wav)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize SpchData with corpus\n",
    "timit_data = pyspch.nn.SpchData(timit_corpus)\n",
    "\n",
    "# read signals (wav-data) from disk ~ 25min\n",
    "sample_rate_wav = 16000\n",
    "timit_data.read_signals(timit_path, sample_rate_wav, extension='.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract TIMIT features (for exercise sessions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mel filterbank cepstral coeffients (mfcc13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A. Mel Frequency Cepstral Coeffients (mfcc13)\n",
    "write_feature_path = write_path + 'data/mfcc13/'\n",
    "\n",
    "# arguments\n",
    "feature_args = {\n",
    "    'spg': None, 'Deltas': None, 'Norm': None,\n",
    "    'sample_rate': 16000, 'f_shift': 0.01, 'f_length': 0.03,\n",
    "    'preemp': 0.97, 'window': 'hamm', 'mode': 'dB',  \n",
    "    'n_mels': 24, 'n_cep': 13 \n",
    "    }\n",
    "\n",
    "# extract and write features\n",
    "pyspch.timit.make_dirs_for_corpus(write_feature_path, timit_corpus)\n",
    "timit_data.extract_features_from_signals(feature_args)\n",
    "timit_data.write_features(write_feature_path) # ~ 25min\n",
    "\n",
    "# write feature_args \n",
    "feature_args_fname = os.path.join(write_feature_path, 'feature_args.json')\n",
    "pyspch.write_json(feature_args, feature_args_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extraction can also be done while reading the signals (wav-data).\n",
    "# This requires less memory (since signals are not kept in memory).\n",
    "# However, here we first load signals, then extract features, such that\n",
    "# different feature extraction's can be performed, without re-reading the signals.\n",
    "if False:\n",
    "    # on the fly looks like:\n",
    "    timit_data.extract_features(timit_path, feature_args, extension='.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mel filterbanks (mel80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B. Mel filterbanks (mel80)\n",
    "write_feature_path = write_path + 'data/mel80/'\n",
    "\n",
    "# arguments\n",
    "feature_args = {\n",
    "    'spg': None, 'Deltas': None, 'Norm': None,\n",
    "    'sample_rate': 16000, 'f_shift': 0.01, 'f_length': 0.03,\n",
    "    'preemp': 0.97, 'window': 'hamm', 'mode': 'dB',\n",
    "    'n_mels': 80, 'n_cep': None\n",
    "    }\n",
    "\n",
    "# extract and write features\n",
    "pyspch.timit.make_dirs_for_corpus(write_feature_path, timit_corpus)\n",
    "timit_data.extract_features_from_signals(feature_args)\n",
    "timit_data.write_features(write_feature_path)\n",
    "\n",
    "# write feature_args \n",
    "feature_args_fname = os.path.join(write_feature_path, 'feature_args.json')\n",
    "pyspch.write_json(feature_args, feature_args_fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filterbanks (fb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C. Filterbanks (fb)\n",
    "write_feature_path = write_path + 'data/fb/'\n",
    "\n",
    "# arguments\n",
    "feature_args = {\n",
    "    'spg': None, 'Deltas': None, 'Norm': None,\n",
    "    'sample_rate': 16000, 'f_shift': 0.01, 'f_length': 0.03,\n",
    "    'preemp': 0.97, 'window': 'hamm', 'mode': 'dB',\n",
    "    'n_mels': None, 'n_cep': None\n",
    "    }\n",
    "\n",
    "# extract and write features\n",
    "pyspch.timit.make_dirs_for_corpus(write_feature_path, timit_corpus)\n",
    "timit_data.extract_features_from_signals(feature_args)\n",
    "timit_data.write_features(write_feature_path)\n",
    "\n",
    "# write feature_args \n",
    "feature_args_fname = os.path.join(write_feature_path, 'feature_args.json')\n",
    "pyspch.write_json(feature_args, feature_args_fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Default setup for exercise sessions\n",
    "\n",
    "Setup saved as pickled dataframe for fast loading:\n",
    "- mfcc13 features:\n",
    "- TIMIT61 phoneme labels: modified in exerice-session to \n",
    "\n",
    "Modified in exerice-session after reading to:\n",
    "- mfcc39 features (by adding delta_ddelta and variance normalisation)\n",
    "- TIMIT41 phoneme labels (by predefined mapping)\n",
    "\n",
    "Setup split into train/test, smaller subsets can be defined analogously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mel Frequency Cepstral Coeffients (mfcc13)\n",
    "# instead of reading, extract features from signals (still in memory) ~ faster\n",
    "read_feature_path = read_path + 'data/mfcc13/'\n",
    "feature_args = pyspch.read_json(read_feature_path + 'feature_args.json')\n",
    "timit_data.extract_features_from_signals(feature_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TIMIT61 phoneme labels (phn)\n",
    "read_label_path = read_path + 'data/segmentation/'\n",
    "label_args = {'pad': 'h#', 'extension': '.phn'}\n",
    "shift = feature_args['f_shift'] * feature_args['sample_rate']\n",
    "timit_data.extract_alligned_labels(read_label_path, shift, label_args['pad'], label_args['extension'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split Spchdata into train/test\n",
    "train_data = timit_data.subset_with_regex(f'.*(train)/.*')\n",
    "test_data = timit_data.subset_with_regex(f'.*(test)/.*')\n",
    "\n",
    "# to dataframe\n",
    "train_df = train_data.to_dataframe()\n",
    "test_df = test_data.to_dataframe()\n",
    "\n",
    "# drop signals (wav-data)\n",
    "train_df.drop(columns=['signals'], inplace=True)\n",
    "test_df.drop(columns=['signals'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write setup to disk\n",
    "write_setup_path = write_path + 'data/mfcc13/'\n",
    "train_df.to_pickle(write_setup_path + 'train.pkl')\n",
    "test_df.to_pickle(write_setup_path + 'test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    \n",
    "    # read from disk\n",
    "    read_setup_path = write_path + 'data/dummy/mfcc13/'\n",
    "    train_df = pd.read_pickle(write_setup_path + 'train.pkl')\n",
    "    test_df = pd.read_pickle(write_setup_path + 'test.pkl')\n",
    "    \n",
    "    # dataframe to SpchData\n",
    "    train_data = pyspch.nn.DataFrame_to_SpchData(train_df)\n",
    "    test_data = pyspch.nn.DataFrame_to_SpchData(test_df)\n",
    "    print(train_data.corpus)\n",
    "    print(test_data.corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other setups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mel Frequency Filterbanks (mel80)\n",
    "read_feature_path = read_path + 'data/mel80/'\n",
    "write_setup_path = write_path + 'data/mel80/'\n",
    "\n",
    "if False:\n",
    "    \n",
    "    feature_args = pyspch.read_json(read_feature_path + 'feature_args.json')\n",
    "    timit_data.extract_features_from_signals(feature_args)\n",
    "    train_data = timit_data.subset_with_regex(f'.*(train)/.*')\n",
    "    test_data = timit_data.subset_with_regex(f'.*(test)/.*')\n",
    "    train_df = train_data.to_dataframe()\n",
    "    test_df = test_data.to_dataframe()\n",
    "    train_df.drop(columns=['signals'], inplace=True)\n",
    "    test_df.drop(columns=['signals'], inplace=True)\n",
    "    train_df.to_pickle(write_setup_path + 'train.pkl')\n",
    "    test_df.to_pickle(write_setup_path + 'test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filterbanks (fb)\n",
    "read_feature_path = read_path + 'data/fb/'\n",
    "write_setup_path = write_path + 'data/fb/'\n",
    "\n",
    "if False:\n",
    "    \n",
    "    feature_args = pyspch.read_json(read_feature_path + 'feature_args.json')\n",
    "    timit_data.extract_features_from_signals(feature_args)\n",
    "    train_data = timit_data.subset_with_regex(f'.*(train)/.*')\n",
    "    test_data = timit_data.subset_with_regex(f'.*(test)/.*')\n",
    "    train_df = train_data.to_dataframe()\n",
    "    test_df = test_data.to_dataframe()\n",
    "    train_df.drop(columns=['signals'], inplace=True)\n",
    "    test_df.drop(columns=['signals'], inplace=True)\n",
    "    train_df.to_pickle(write_setup_path + 'train.pkl')\n",
    "    test_df.to_pickle(write_setup_path + 'test.pkl')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "07bbb230afa188f6fcf784790a512a027d4aaebd8b449a47936f42b92e92fbab"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 ('pyspch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
