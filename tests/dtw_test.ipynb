{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DTW TEST\n",
    "The DTW module contains implementations of string based DP with as main purpose the use in evaluation of speech recognition systems   \n",
    "+ DP routines\n",
    "    - levenshtein(): \n",
    "        - computes the vanilla Levenshtein distance, i.e. #S+#I+#D\n",
    "        - no backtracking, hence only composite distance / error rate \n",
    "    - dtw(): \n",
    "        - computes a weighted edit distance\n",
    "        - allows for prior normalization\n",
    "        - allowing Substitutions, Insertion, Deletions \n",
    "        - returns the alignment and #S, #I, #D separated out\n",
    "    - both routines take lists of tokens as inputs, hence applicable to both word or character tokens \n",
    "    \n",
    "24/03/2022:  not fully functional yet in v0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional install of the pyspch package\n",
    "#!pip install git+https://github.com/compi1234/pyspch.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do all the imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import timeit\n",
    "from pyspch import dtw \n",
    "#import Normalizer as Norm\n",
    "from IPython.display import display, HTML\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "# help(dtw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    div#notebook-container    { width: 95%; }\n",
       "    div#menubar-container     { width: 65%; }\n",
       "    div#maintoolbar-container { width: 99%; }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML(data=\"\"\"\n",
    "<style>\n",
    "    div#notebook-container    { width: 95%; }\n",
    "    div#menubar-container     { width: 65%; }\n",
    "    div#maintoolbar-container { width: 99%; }\n",
    "</style>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module pyspch.dtw in pyspch:\n",
      "\n",
      "NAME\n",
      "    pyspch.dtw\n",
      "\n",
      "DESCRIPTION\n",
      "    The modules in `dtw.py` contain basic implementations of Levenshtein and Weighted Edit Distance DP matching\n",
      "    The main purpose is for didactic demonstrations of  small systems \n",
      "    \n",
      "    Created on Jan 13, 2021\n",
      "            \n",
      "    @author: compi\n",
      "\n",
      "FUNCTIONS\n",
      "    alignment_to_counts(df)\n",
      "        count nSUB/nINS/nDEL, nTOT and Err from an alignment dataframe\n",
      "        Parameters:\n",
      "        -----------\n",
      "                    df  type DataFrame, alignment as provided e.g. by wedit()\n",
      "        Returns:\n",
      "        --------\n",
      "                    (nsub,nins,ndel,ntot,err)   counts of SUB/INS/DEL and TOT and Err in %\n",
      "    \n",
      "    edit_distance(x=[], y=[], wS=1.0, wI=1.0, wD=1.0, Verbose=False)\n",
      "        Weighted Edit Distance by DTW aligment allowing for SUB/INS/DEL\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        x : list (or str) \n",
      "            tokens in hypothesis/test\n",
      "        y : list (or str)\n",
      "            tokens in reference\n",
      "        \n",
      "        wS, wI, wD: float, defaults to 1.   \n",
      "            edit costs for Substition, Insertion, Deletion\n",
      "        \n",
      "        Verbose : boolean, default=False\n",
      "            if True highly Verbose printing of internal results (trellis, backtrace, .. )\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "            dist : float\n",
      "                weighted edit distance\n",
      "            alignment : DataFrame\n",
      "                alignment path as DataFrame with columns [ 'x', 'y', 'OPS' ]\n",
      "            cts : list of int\n",
      "                counts of [nsub,nins,ndel,Ny,nCx,nCy]\n",
      "                if Compounds is False then last 2 arguments will be 0\n",
      "            trellis :\n",
      "                2D nd-array with trellis values\n",
      "    \n",
      "    lev_distance(seq1, seq2)\n",
      "         Levenshtein Distance\n",
      "             Finds the symmetric Levenshtein distance as the sum of INS/DEL/SUB \n",
      "             There is no backtracking, and no separate maintenance of INS/SUB/DEL \n",
      "             Each operation adds '1.' to the cost\n",
      "         \n",
      "         Parameters\n",
      "         ----------\n",
      "             seq1 : list\n",
      "                 tokens in list1 (either hypothesis or test)\n",
      "             seq2 : list\n",
      "                 tokens in list2 (the other)\n",
      "         \n",
      "         Returns\n",
      "        --------\n",
      "             dist : int\n",
      "                 total number of edits\n",
      "    \n",
      "    print_align(align)\n",
      "        prints an alignment given in DataFrame format\n",
      "    \n",
      "    print_edit_results(cts=None, align=None, trellis=None, Display=True)\n",
      "        pretty prints results from edit_distance()\n",
      "    \n",
      "    tokenizer(text, tolower=False)\n",
      "        convert a text to a list of tokens\n",
      "\n",
      "FILE\n",
      "    c:\\users\\compi\\nextcloud\\github\\pyspch\\pyspch\\dtw.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(dtw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Extra Utilities\n",
    "- print_results(): for printing alignment and scores of DTW matching\n",
    "- score_corpus(): for global scoring of a corpus given by a list of paired sentences [reference,test]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_edist_results(cts=None,df_align=None,trellis=None,Display=True):\n",
    "    if trellis is not None:\n",
    "        print(\" == TRELLIS == \")\n",
    "    if df_align is not None:\n",
    "        print(\"\\n == ALIGNMENT == \")\n",
    "        with pd.option_context('display.max_rows', None, 'display.max_columns', None): \n",
    "            if(Display):\n",
    "                display(df_align.T)\n",
    "            else:\n",
    "                print(df_align.T)\n",
    "    if cts is not None:\n",
    "        print(\"\\n == SCORE ==\")\n",
    "        print(\"#S=%d, #I=%d, #D=%d for %d tokens \\nErr=%.2f%%\" % cts )\n",
    "        \n",
    "def score_corpus(corpus, Verbose = False, Display = True):\n",
    "    Nsub = 0\n",
    "    Nins = 0\n",
    "    Ndel = 0\n",
    "    Ntot = 0\n",
    "    for [reference,result] in corpus:\n",
    "        ref = dtw.tokenizer(reference)\n",
    "        hyp = dtw.tokenizer(result)\n",
    "        df_align, cts, _ = dtw.wedit(hyp,ref)\n",
    "        \n",
    "        if(Verbose):\n",
    "            print(\"Reference:\",ref)\n",
    "            print(\"Output(test):    \",hyp)\n",
    "            print_edist_results(df_align=df_align)\n",
    "        \n",
    "        Nsub += cts[0]\n",
    "        Nins += cts[1]\n",
    "        Ndel += cts[2]\n",
    "        Ntot += cts[3]\n",
    "\n",
    "    print(\"\\n ++ CORPUS RESULTS ++ \")\n",
    "    print(\"\\n#S=%d, #I=%d, #D=%d for %d tokens\" % (Nsub,Nins,Ndel,Ntot) )\n",
    "    print(\"Error Rate: %5.2f%%\" % (100.*(Nsub+Nins+Ndel)/Ntot)  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Levenshtein and Weighted Edit Distance for string matching (tokens=:characters)\n",
    "- character strings are essentially a list of characters and can be passed directly as input and reference sequence\n",
    "- change Verbose to True to see all essential internal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Levenshtein Distance:  4.0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-7e0e2718d4c0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Levenshtein Distance: \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlevdist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0malignment\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcts\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0medit_distance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mVerbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mprint_edist_results\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_align\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0malignment\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "ref = \"boeken\"\n",
    "hyp =  \"broekske\"\n",
    "y = ref\n",
    "x = hyp\n",
    "levdist = dtw.lev_distance(x,y)\n",
    "print(\"Levenshtein Distance: \",levdist)\n",
    "#\n",
    "alignment,cts,_ = dtw.edit_distance(x,y,Verbose=False)\n",
    "print_edist_results(df_align=alignment,cts=cts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Levenshtein and Weighted Edit Distance for sentence matching (tokens=:words)\n",
    "The tokenizer used is simply the default Python split(), with optional conversion to lower case   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input(reference): to recognize speech is the topic of this course\n",
      "Output(test):     to wreck a nice beach seems of this month\n",
      "\n",
      "--- Character DTW Match on Sentence ----- \n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'pyspch.dtw' has no attribute 'levenshtein'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-61017b462964>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mref\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhyp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mlevdist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlevenshtein\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Levenshtein Distance: \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlevdist\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'pyspch.dtw' has no attribute 'levenshtein'"
     ]
    }
   ],
   "source": [
    "# pd.set_option('display.max_rows', None, 'display.max_columns', None)\n",
    "# sentence matching\n",
    "ref = \"to recognize speech is the topic of this course\"\n",
    "hyp =  \"to wreck a nice beach seems of this month\"\n",
    "print(\"Input(reference):\",ref)\n",
    "print(\"Output(test):    \",hyp)\n",
    "#\n",
    "print(\"\\n--- Character DTW Match on Sentence ----- \")\n",
    "y = ref\n",
    "x = hyp\n",
    "levdist = dtw.levenshtein(x,y)\n",
    "print(\"Levenshtein Distance: \",levdist,\"\\n\")\n",
    "\n",
    "alignment,cts,_ = dtw.wedit(x,y,Verbose=False)\n",
    "print_edist_results(df_align=alignment,cts=cts)\n",
    "\n",
    "print(\"\\n--- Word DTW Match on Sentence ----- \")\n",
    "y = dtw.tokenizer(ref)\n",
    "x = dtw.tokenizer(hyp)\n",
    "levdist = dtw.levenshtein(x,y)\n",
    "print(\"Levenshtein Distance: \",levdist,\"\\n\")\n",
    "\n",
    "alignment,cts,_ = dtw.wedit(x,y,Verbose=False)\n",
    "print_edist_results(df_align=alignment,cts=cts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus1 = [ \n",
    "[ \"ASTRONOMERS SAY THAT THE EARTH'S FATE IS SEALED\",\n",
    "  \" MR. ARMOUR SAY THAT THE EARTH'S FETISH  SEALED\"],\n",
    "[ 'GLASNOST HAS ALSO BEEN GOOD TO LAWRENCE LEIGHTON SMITH',\n",
    "  'CLASS NOSED HAD ALSO BEEN GOOD TO LAWRENCE FLEET AND SMITH'],\n",
    "[ \"AS MS. KENDALL AND MR. LOUW SEE IT SOUTH AFRICA'S CENTRAL GOVERNMENT IS LIKE A BIG LUMBERING TANK\",\n",
    "  \"AS MS. SCANDAL AND MR. LOWE C. AT SOUTH AFRICA'S CENTRAL GOVERNMENT IS LIKE A BIG LUMBER INK TANK\"],\n",
    "[ \"MR. WANG IS RELATIVELY YOUNG FOR HIS JOB UPSETTING OLDER COLLEAGUES\",\n",
    "  \"MR. WANG IS RELATIVELY YOUNG FIRST JOB KIND OF SETS OLDER COLLEAGUES\"]\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pyspch.dtw' has no attribute 'wedit'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-28757bffaec8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mscore_corpus\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mVerbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-6-9b6371bf3a07>\u001b[0m in \u001b[0;36mscore_corpus\u001b[1;34m(corpus, Verbose, Display)\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mref\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreference\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mhyp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0mdf_align\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwedit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhyp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mVerbose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'pyspch.dtw' has no attribute 'wedit'"
     ]
    }
   ],
   "source": [
    "score_corpus(corpus1,Verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
