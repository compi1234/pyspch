{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramFiles\\miniconda3\\envs\\pyspch_edit\\lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pyspch\n",
    "import pyspch.nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths \n",
    "\n",
    "# public = /users/spraak/spchlab/public_html/pyspch/timit/ (final project)\n",
    "# private = /esat/spchtemp/scratch/bvandyck/timit/ (dev project, training models on HTCondor)\n",
    "remote_path = 'https://homes.esat.kuleuven.be/~spchlab/pyspch/timit/'\n",
    "\n",
    "if True:\n",
    "    # (@remote, personal machine, bvandyck) \n",
    "    timit_path = 'W:/timit/CDdata/timit/' # to extract corpus, features, labels\n",
    "    write_path = 'Z:/scratch/bvandyck/timit/' # to write corpus, features, labels\n",
    "    read_path = 'Z:/scratch/bvandyck/timit/' # to read corpus, features, labels\n",
    "\n",
    "if False:\n",
    "    # (@esat, bvandyck)\n",
    "    timit_path = '/users/spraak/spchdata/timit/CDdata/timit/' # to extract corpus, features, labels\n",
    "    write_path = '/esat/spchtemp/scratch/bvandyck/timit/' # to write corpus, features, labels\n",
    "    read_path = '/esat/spchtemp/scratch/bvandyck/timit/' # to read corpus, features, labels\n",
    "    \n",
    "if False:\n",
    "    # (@esat, spchlab)\n",
    "    timit_path = '/users/spraak/spchdata/timit/CDdata/timit/' # to extract corpus, features, labels\n",
    "    write_path = '/users/spraak/spchlab/public_html/pyspch/timit/' # to write corpus, features, labels\n",
    "    read_path = '/users/spraak/spchlab/public_html/pyspch/timit/' # to read corpus, features, labels\n",
    "\n",
    "os.chdir(write_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare (or read) TIMIT corpus "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy corpus contains 5 files\n"
     ]
    }
   ],
   "source": [
    "# prepare TIMIT corpus \n",
    "prepare_corpus = True\n",
    "read_corpus = True\n",
    "write_corpus_path = write_path + 'data/dummy/'\n",
    "read_corpus_path = read_path + 'data/dummy/'\n",
    "\n",
    "if prepare_corpus:\n",
    "    \n",
    "    # get corpus from directory \n",
    "    timit_corpus = pyspch.timit.get_timit_corpus(timit_path) \n",
    "    timit_corpus = timit_corpus[:5]\n",
    "    \n",
    "    # write corpus to disk\n",
    "    os.makedirs(write_corpus_path, exist_ok=True)\n",
    "    pyspch.write_txt(timit_corpus, write_corpus_path + 'dummy.corpus')\n",
    "\n",
    "    # extract meta data and write to disk\n",
    "    timit_meta = pyspch.timit.get_timit_metadata(timit_corpus)\n",
    "    timit_meta.to_csv(write_corpus_path + 'dummy.meta', sep='\\t', index=False, header=False)\n",
    "\n",
    "if read_corpus:\n",
    "    \n",
    "    # read corpus and meta data\n",
    "    timit_corpus = pyspch.read_data_file(read_corpus_path + 'dummy.corpus')\n",
    "    meta = pyspch.read_dataframe(read_corpus_path + \"dummy.meta\")\n",
    "   \n",
    "# print\n",
    "print(f'Dummy corpus contains {len(timit_corpus)} files')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read TIMIT data (wav)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize SpchData with corpus\n",
    "timit_data = pyspch.nn.SpchData(timit_corpus)\n",
    "\n",
    "# read signals (wav-data) from disk ~ 25min\n",
    "sample_rate_wav = 16000\n",
    "timit_data.read_signals(timit_path, sample_rate_wav, extension='.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract TIMIT features (for exercise sessions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mel filterbank cepstral coeffients (mfcc13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A. Mel Frequency Cepstral Coeffients (mfcc13)\n",
    "write_feature_path = write_path + 'data/dummy/mfcc13/'\n",
    "\n",
    "# arguments\n",
    "feature_args = {\n",
    "    'spg': None, 'Deltas': None, 'Norm': None,\n",
    "    'sample_rate': 16000, 'f_shift': 0.01, 'f_length': 0.03,\n",
    "    'preemp': 0.97, 'window': 'hamm', 'mode': 'dB',  \n",
    "    'n_mels': 24, 'n_cep': 13 \n",
    "    }\n",
    "\n",
    "# extract and write features\n",
    "pyspch.timit.make_dirs_for_corpus(write_feature_path, timit_corpus)\n",
    "timit_data.extract_features_from_signals(feature_args)\n",
    "timit_data.write_features(write_feature_path) # ~ 25min\n",
    "\n",
    "# write feature_args \n",
    "feature_args_fname = os.path.join(write_feature_path, 'feature_args.json')\n",
    "pyspch.write_json(feature_args, feature_args_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extraction can also be done while reading the signals (wav-data).\n",
    "# This requires less memory (since signals are not kept in memory).\n",
    "# However, here we first load signals, then extract features, such that\n",
    "# different feature extraction's can be performed, without re-reading the signals.\n",
    "if False:\n",
    "    # on the fly looks like:\n",
    "    timit_data.extract_features(timit_path, feature_args, extension='.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mel filterbanks (mel80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B. Mel filterbanks (mel80)\n",
    "write_feature_path = write_path + 'data/dummy/mel80/'\n",
    "\n",
    "# arguments\n",
    "feature_args = {\n",
    "    'spg': None, 'Deltas': None, 'Norm': None,\n",
    "    'sample_rate': 16000, 'f_shift': 0.01, 'f_length': 0.03,\n",
    "    'preemp': 0.97, 'window': 'hamm', 'mode': 'dB',\n",
    "    'n_mels': 80, 'n_cep': None\n",
    "    }\n",
    "\n",
    "# extract and write features\n",
    "pyspch.timit.make_dirs_for_corpus(write_feature_path, timit_corpus)\n",
    "timit_data.extract_features_from_signals(feature_args)\n",
    "timit_data.write_features(write_feature_path)\n",
    "\n",
    "# write feature_args \n",
    "feature_args_fname = os.path.join(write_feature_path, 'feature_args.json')\n",
    "pyspch.write_json(feature_args, feature_args_fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filterbanks (fb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C. Filterbanks (fb)\n",
    "write_feature_path = write_path + 'data/dummy/fb/'\n",
    "\n",
    "# arguments\n",
    "feature_args = {\n",
    "    'spg': None, 'Deltas': None, 'Norm': None,\n",
    "    'sample_rate': 16000, 'f_shift': 0.01, 'f_length': 0.03,\n",
    "    'preemp': 0.97, 'window': 'hamm', 'mode': 'dB',\n",
    "    'n_mels': None, 'n_cep': None\n",
    "    }\n",
    "\n",
    "# extract and write features\n",
    "pyspch.timit.make_dirs_for_corpus(write_feature_path, timit_corpus)\n",
    "timit_data.extract_features_from_signals(feature_args)\n",
    "timit_data.write_features(write_feature_path)\n",
    "\n",
    "# write feature_args \n",
    "feature_args_fname = os.path.join(write_feature_path, 'feature_args.json')\n",
    "pyspch.write_json(feature_args, feature_args_fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Default setup for exercise sessions\n",
    "\n",
    "Setup saved as pickled dataframe for fast loading:\n",
    "- mfcc13 features:\n",
    "- TIMIT61 phoneme labels: modified in exerice-session to \n",
    "\n",
    "Modified in exerice-session after reading to:\n",
    "- mfcc39 features (by adding delta_ddelta and variance normalisation)\n",
    "- TIMIT41 phoneme labels (by predefined mapping)\n",
    "\n",
    "Setup split into train/test, smaller subsets can be defined analogously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mel Frequency Cepstral Coeffients (mfcc13)\n",
    "# instead of reading, extract features from signals (still in memory) ~ faster\n",
    "read_feature_path = read_path + 'data/dummy/mfcc13/'\n",
    "feature_args = pyspch.read_json(read_feature_path + 'feature_args.json')\n",
    "timit_data.extract_features_from_signals(feature_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TIMIT61 phoneme labels (phn)\n",
    "read_label_path = read_path + 'data/segmentation/'\n",
    "label_args = {'pad': 'h#', 'extension': '.phn'}\n",
    "shift = feature_args['f_shift'] * feature_args['sample_rate']\n",
    "timit_data.extract_alligned_labels(read_label_path, shift, label_args['pad'], label_args['extension'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split Spchdata into train/test\n",
    "train_data = timit_data.subset_with_regex(f'.*(train)/.*')\n",
    "test_data = timit_data.subset_with_regex(f'.*(test)/.*')\n",
    "\n",
    "# to dataframe\n",
    "train_df = train_data.to_dataframe()\n",
    "test_df = test_data.to_dataframe()\n",
    "\n",
    "# drop signals (wav-data)\n",
    "train_df.drop(columns=['signals'], inplace=True)\n",
    "test_df.drop(columns=['signals'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write setup to disk\n",
    "write_setup_path = write_path + 'data/dummy/mfcc13/'\n",
    "train_df.to_pickle(write_setup_path + 'train.pkl')\n",
    "test_df.to_pickle(write_setup_path + 'test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read from disk\n",
    "read_setup_path = write_path + 'data/dummy/mfcc13/'\n",
    "train_df = pd.read_pickle(write_setup_path + 'train.pkl')\n",
    "test_df = pd.read_pickle(write_setup_path + 'test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-8.89878540e+01, -8.85344086e+01, -8.88102875e+01, ...,\n",
       "         -8.24185867e+01, -8.41160965e+01, -8.48701477e+01],\n",
       "        [-3.24137259e+00, -3.68005610e+00, -2.64687681e+00, ...,\n",
       "         -2.06441164e+00, -2.72634339e+00, -2.04581308e+00],\n",
       "        [ 1.57882619e+00,  1.62022996e+00,  1.85508585e+00, ...,\n",
       "         -1.05803418e+00, -7.73265362e-01, -3.21130246e-01],\n",
       "        ...,\n",
       "        [ 4.18425500e-01,  1.89767331e-01, -3.21906000e-01, ...,\n",
       "         -8.03407073e-01,  1.38152689e-01, -3.14693093e-01],\n",
       "        [-4.01160866e-02, -6.22037351e-02,  1.05652511e-01, ...,\n",
       "          4.79777753e-01,  1.86404407e-01,  3.36148262e-01],\n",
       "        [-2.02238187e-01, -1.24567240e-01,  1.42143413e-01, ...,\n",
       "         -1.39512837e+00, -1.03967476e+00, -1.03731535e-01]], dtype=float32),\n",
       " array([[-9.0913391e+01, -9.1210777e+01, -9.1849274e+01, ...,\n",
       "         -7.9598297e+01, -8.0518440e+01, -7.9906700e+01],\n",
       "        [-4.8179998e+00, -4.9821968e+00, -4.5333366e+00, ...,\n",
       "         -3.6911516e+00, -4.1874919e+00, -4.3455076e+00],\n",
       "        [ 1.2942652e+00,  1.9394976e+00,  1.9416068e+00, ...,\n",
       "         -3.9902869e-01, -8.4771627e-01, -1.3475738e+00],\n",
       "        ...,\n",
       "        [ 8.1626020e-02, -2.1937150e-01, -1.5905328e-01, ...,\n",
       "          1.2151675e+00,  8.3295059e-01,  6.5377629e-01],\n",
       "        [ 4.1253477e-01,  4.2224047e-01, -1.3358781e-01, ...,\n",
       "         -1.0568547e-01, -2.7511513e-01, -5.9244081e-02],\n",
       "        [-4.1965734e-02, -2.2267054e-01,  5.1604141e-02, ...,\n",
       "         -1.6296605e+00, -9.8726708e-01, -4.6139106e-01]], dtype=float32),\n",
       " array([[-8.7747665e+01, -8.7567513e+01, -8.1204704e+01, ...,\n",
       "         -8.4389252e+01, -8.5113373e+01, -8.6119026e+01],\n",
       "        [-2.4821284e+00, -2.7400210e+00,  1.9767276e+00, ...,\n",
       "         -1.6262977e+00, -1.3952070e+00, -1.8719244e+00],\n",
       "        [ 1.4620488e+00,  1.6250150e+00, -9.8540312e-01, ...,\n",
       "          3.2246751e-01,  1.8015850e-01, -5.6571257e-01],\n",
       "        ...,\n",
       "        [ 2.4419251e-01, -2.9283628e-02, -1.7322795e-01, ...,\n",
       "         -3.1911534e-01, -2.4176572e-01,  2.1435899e-01],\n",
       "        [-8.2513608e-02,  2.3335758e-01,  3.5792660e-02, ...,\n",
       "          9.2964306e-02,  6.7060620e-02,  4.1100553e-01],\n",
       "        [-2.3296302e-02, -2.1689904e-01,  2.4241917e-01, ...,\n",
       "         -5.0044304e-01, -1.0758441e-01, -3.8069573e-01]], dtype=float32),\n",
       " array([[-8.9642860e+01, -8.9856148e+01, -8.9789604e+01, ...,\n",
       "         -7.9646225e+01, -8.0010078e+01, -7.9870087e+01],\n",
       "        [-3.3492739e+00, -3.2858667e+00, -3.4383128e+00, ...,\n",
       "         -3.1746011e+00, -4.0531998e+00, -3.2996354e+00],\n",
       "        [ 1.7597227e+00,  1.5523227e+00,  1.6707530e+00, ...,\n",
       "         -1.7009485e+00, -2.4900494e+00, -2.4843559e+00],\n",
       "        ...,\n",
       "        [ 1.0709411e-01, -9.2311792e-02,  3.5605595e-02, ...,\n",
       "          1.2270734e-01,  5.2290952e-01,  8.5418582e-01],\n",
       "        [-1.7941116e-01,  4.7632460e-02,  4.7195852e-03, ...,\n",
       "          6.0956848e-01,  9.5023263e-01,  6.6521770e-01],\n",
       "        [-8.2649767e-02,  1.0669983e-01,  1.4946139e-01, ...,\n",
       "          7.1585476e-01, -1.2126959e-01, -2.9571074e-01]], dtype=float32),\n",
       " array([[-8.3296394e+01, -8.3070908e+01, -8.3003143e+01, ...,\n",
       "         -8.2601761e+01, -8.1847527e+01, -8.2401390e+01],\n",
       "        [-5.7150583e+00, -5.9341955e+00, -5.7012300e+00, ...,\n",
       "         -3.7888837e+00, -3.9794037e+00, -3.8054814e+00],\n",
       "        [-8.6269933e-01, -1.0601947e+00, -1.1138107e+00, ...,\n",
       "          5.6036907e-01,  7.7770054e-01,  2.1188286e-01],\n",
       "        ...,\n",
       "        [ 2.4250430e-01, -3.5300553e-02, -1.7654052e-01, ...,\n",
       "         -3.7252441e-02,  1.0026974e-01,  8.5863829e-01],\n",
       "        [ 7.7758235e-01,  1.4470658e-01,  3.9049774e-01, ...,\n",
       "          8.1031877e-01, -2.4176686e-01, -6.8951452e-01],\n",
       "        [-6.8401802e-01, -7.0380092e-01, -4.1699432e-02, ...,\n",
       "          4.5335045e-01, -1.3015661e-01, -1.2294830e+00]], dtype=float32)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataframe to SpchData\n",
    "train_data = pyspch.nn.SpchData_from_dataframe(train_df)\n",
    "test_data = pyspch.nn.SpchData_from_dataframe(test_df)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "07bbb230afa188f6fcf784790a512a027d4aaebd8b449a47936f42b92e92fbab"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 ('pyspch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
